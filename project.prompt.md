Instrucci贸n: Crea un proyecto completo de prueba de concepto (Proof of Concept - PoC) para Kafka Streams utilizando Java 21, Spring Boot 3, Apache Kafka (para la configuraci贸n y testing) y una base de datos H2 en memoria.

El proyecto debe demostrar la funcionalidad de Kafka Streams con tres casos de uso espec铆ficos y exponer una API REST para la interacci贸n.

 Requisitos del Proyecto
1. Estructura y Tecnolog铆as
Lenguaje: Java 21.

Framework: Spring Boot 3.

Base de Datos: H2 (en modo embebido para persistencia simple).

Componentes:

Una aplicaci贸n Spring Boot que contenga los servicios de Kafka Producer, Kafka Streams y la API REST.

Clases de dominio/DTOs para representar los eventos.

2. Configuraci贸n de T贸picos
Define los siguientes t贸picos (deben ser configurables en application.yml):

input-topic: T贸pico de entrada para los casos de uso 1 y 2.

actions-topic: T贸pico de entrada para el caso de uso 3.

output-topic-transformed: T贸pico de salida para el caso de uso 1.

output-topic-json-converted: T贸pico de salida para el caso de uso 2.

output-topic-action-a: T贸pico de salida para la primera acci贸n del caso 3.

output-topic-action-b: T贸pico de salida para la segunda acci贸n del caso 3.

3. Implementaci贸n de Casos de Uso (Kafka Streams)
Implementa una clase de configuraci贸n de Kafka Streams (KafkaStreamsConfig) que defina la topolog铆a para manejar los tres casos de uso simult谩neamente.

Caso de Uso	T贸pico de Entrada	L贸gica de Transformaci贸n	T贸pico(s) de Salida
1. Transformaci贸n de Contenido	input-topic	Recibe un evento (ej. SimpleEvent {id, payload, timestamp}). Transforma solo el campo payload (ej. a may煤sculas o a帽adiendo un prefijo) manteniendo la estructura del evento y la clave.	output-topic-transformed
2. Conversi贸n de Esquema JSON	input-topic	Recibe un evento JSON con un formato (ej. LegacyEvent {old_field_name, value}). Convierte este JSON a un formato completamente nuevo (ej. NewFormatEvent {newFieldName, data}), alterando la estructura y los nombres de campo.	output-topic-json-converted
3. Divisi贸n y Publicaci贸n (Routing)	actions-topic	Recibe un evento gen茅rico (ej. GenericAction {actionType, details}). El campo actionType determina la acci贸n. Separar el stream basado en actionType (ej. type=A y type=B). Transformar cada sub-stream independientemente y enviarlo a su t贸pico dedicado como dos eventos separados.	output-topic-action-a y output-topic-action-b

Export to Sheets
4. Persistencia y API REST
Persistencia (H2):

Crea una entidad JPA (ProcessedEvent) para almacenar los resultados finales de los streams.

El servicio de Streams debe tener un consumidor secundario o un servicio de persistencia que escuche los t贸picos de salida (output-topic-transformed, output-topic-json-converted, output-topic-action-a, output-topic-action-b) y persista los datos en H2.

API REST:

POST /api/events/simple: Recibe un evento para el Caso 1 y 2, y lo publica en input-topic.

POST /api/events/action: Recibe un evento para el Caso 3, y lo publica en actions-topic.

GET /api/events/processed: Consulta todos los registros de la tabla ProcessedEvent de H2 para verificar los resultados.

Instrucci贸n Final: Proporciona todo el c贸digo fuente organizado en archivos (clases de Java, configuraci贸n YAML, DTOs, etc.), asegurando que el proyecto sea ejecutable y que las dependencias de Maven est茅n correctamente definidas. Incluye comentarios explicativos en el c贸digo de Kafka Streams.

Explicaci贸n del Prompt para el Generador 
Este prompt es efectivo porque:

Define el Stack: Especifica las versiones de Java, Spring Boot y el uso de H2, lo cual es crucial para la generaci贸n de c贸digo.

Detalla los Casos de Uso: Proporciona un esquema claro de la entrada, la transformaci贸n y la salida para cada uno de los tres requisitos, incluyendo el uso de los m茅todos clave de Kafka Streams como mapValues, map, y branch/to.

Especifica la Interacci贸n (API): Define los endpoints exactos que el generador debe crear para la prueba manual del PoC (producci贸n y consulta).

A帽ade Persistencia: Incluir la persistencia con H2 obliga al generador a crear un mecanismo (posiblemente un @KafkaListener) para consumir los resultados finales del stream, cerrando el ciclo de la prueba de concepto.