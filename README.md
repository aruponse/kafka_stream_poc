# Kafka Streams Proof of Concept (PoC)

Este proyecto es una prueba de concepto completa que demuestra el uso de **Kafka Streams** con **Java 21**, **Spring Boot 3**, **Apache Kafka** y una base de datos **H2** en memoria.

## ğŸ¯ Casos de Uso Implementados

### 1. TransformaciÃ³n de Contenido (Content Transformation)
- **Input**: `SimpleEvent` en el tÃ³pico `input-topic`
- **Procesamiento**: Transforma el campo `payload` a mayÃºsculas y aÃ±ade prefijo "TRANSFORMED:"
- **Output**: Evento transformado en el tÃ³pico `output-topic-transformed`

### 2. ConversiÃ³n de Esquema JSON (JSON Schema Conversion)
- **Input**: `LegacyEvent` en el tÃ³pico `input-topic`
- **Procesamiento**: Convierte de formato legacy a `NewFormatEvent`
- **Output**: Evento convertido en el tÃ³pico `output-topic-json-converted`

### 3. Enrutamiento y DivisiÃ³n (Routing and Division)
- **Input**: `GenericAction` en el tÃ³pico `actions-topic`
- **Procesamiento**: Enruta segÃºn `actionType` (A o B) con transformaciones especÃ­ficas
- **Output**: Eventos procesados en `output-topic-action-a` y `output-topic-action-b`

## ğŸ—ï¸ Arquitectura del Proyecto

```
src/main/java/com/example/kafkastream/
â”œâ”€â”€ KafkaStreamPocApplication.java          # AplicaciÃ³n principal
â”œâ”€â”€ config/
â”‚   â””â”€â”€ KafkaStreamsConfig.java            # ConfiguraciÃ³n de Kafka Streams
â”œâ”€â”€ controller/
â”‚   â””â”€â”€ EventController.java               # REST API endpoints
â”œâ”€â”€ dto/
â”‚   â”œâ”€â”€ SimpleEvent.java                   # DTO para Caso 1
â”‚   â”œâ”€â”€ LegacyEvent.java                   # DTO para Caso 2 (input)
â”‚   â”œâ”€â”€ NewFormatEvent.java                # DTO para Caso 2 (output)
â”‚   â””â”€â”€ GenericAction.java                 # DTO para Caso 3
â”œâ”€â”€ model/
â”‚   â””â”€â”€ ProcessedEvent.java                # Entidad JPA para persistencia
â”œâ”€â”€ repository/
â”‚   â””â”€â”€ ProcessedEventRepository.java      # Repositorio JPA
â””â”€â”€ service/
    â”œâ”€â”€ ProcessedEventService.java         # Servicio de negocio
    â””â”€â”€ KafkaPersistenceService.java       # Consumidor para persistencia
```

## ğŸš€ Requisitos Previos

1. **Java 21** instalado
2. **Maven 3.8+** instalado
3. **Apache Kafka** ejecutÃ¡ndose en `localhost:9092`

### Iniciar Kafka (usando Confluent Platform o Apache Kafka)

```bash
# Iniciar Zookeeper
bin/zookeeper-server-start etc/kafka/zookeeper.properties

# Iniciar Kafka Server
bin/kafka-server-start etc/kafka/server.properties
```

## ğŸ“¦ CompilaciÃ³n y EjecuciÃ³n

### 1. Compilar el proyecto
```bash
cd kafka_stream_poc
mvn clean compile
```

### 2. Ejecutar la aplicaciÃ³n
```bash
mvn spring-boot:run
```

### 3. Verificar que estÃ¡ ejecutÃ¡ndose
La aplicaciÃ³n estarÃ¡ disponible en: `http://localhost:8081`

## ğŸ§ª Testing de los Casos de Uso

### Caso 1: TransformaciÃ³n de Contenido

**Enviar SimpleEvent:**
```bash
curl -X POST http://localhost:8081/api/events/simple/typed \
  -H "Content-Type: application/json" \
  -d '{
    "id": "simple-001",
    "payload": "hello world",
    "timestamp": 1640995200000
  }'
```

### Caso 2: ConversiÃ³n de Esquema JSON

**Enviar LegacyEvent:**
```bash
curl -X POST http://localhost:8081/api/events/legacy \
  -H "Content-Type: application/json" \
  -d '{
    "old_field_name": "legacy_field",
    "value": "legacy data"
  }'
```

### Caso 3: Enrutamiento y DivisiÃ³n

**Enviar GenericAction Tipo A:**
```bash
curl -X POST http://localhost:8081/api/events/action \
  -H "Content-Type: application/json" \
  -d '{
    "actionType": "A",
    "details": "Process action type A"
  }'
```

**Enviar GenericAction Tipo B:**
```bash
curl -X POST http://localhost:8081/api/events/action \
  -H "Content-Type: application/json" \
  -d '{
    "actionType": "B",
    "details": "Process action type B"
  }'
```

### Consultar Eventos Procesados

**Ver todos los eventos procesados:**
```bash
curl -X GET http://localhost:8081/api/events/processed
```

**Ver estadÃ­sticas:**
```bash
curl -X GET http://localhost:8081/api/events/processed/stats
```

**Filtrar por tipo de evento:**
```bash
curl -X GET "http://localhost:8081/api/events/processed?eventType=SIMPLE_EVENT_TRANSFORMED"
```

## ğŸ’¾ Base de Datos H2

### Acceder a la Consola H2
- URL: `http://localhost:8081/h2-console`
- JDBC URL: `jdbc:h2:mem:testdb`
- Username: `sa`
- Password: (vacÃ­o)

### Consultar la Tabla de Eventos Procesados
```sql
SELECT * FROM processed_events ORDER BY processed_at DESC;
```

## ğŸ“‹ Endpoints de la API REST

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| POST | `/api/events/simple` | Publicar evento genÃ©rico (SimpleEvent o LegacyEvent) |
| POST | `/api/events/simple/typed` | Publicar SimpleEvent tipado |
| POST | `/api/events/legacy` | Publicar LegacyEvent tipado |
| POST | `/api/events/action` | Publicar GenericAction |
| GET | `/api/events/processed` | Obtener todos los eventos procesados |
| GET | `/api/events/processed/stats` | Obtener estadÃ­sticas de procesamiento |
| DELETE | `/api/events/processed` | Eliminar todos los eventos procesados |

## ğŸ”§ ConfiguraciÃ³n

### TÃ³picos de Kafka (configurables en `application.yml`)
- `input-topic`: Entrada para casos 1 y 2
- `actions-topic`: Entrada para caso 3
- `output-topic-transformed`: Salida para caso 1
- `output-topic-json-converted`: Salida para caso 2
- `output-topic-action-a`: Salida para acciones tipo A
- `output-topic-action-b`: Salida para acciones tipo B

### Variables de ConfiguraciÃ³n Principales
```yaml
app:
  kafka:
    topics:
      input-topic: input-topic
      actions-topic: actions-topic
      output-topic-transformed: output-topic-transformed
      output-topic-json-converted: output-topic-json-converted
      output-topic-action-a: output-topic-action-a
      output-topic-action-b: output-topic-action-b
```

## ğŸ› Troubleshooting

### Problema: Kafka no estÃ¡ ejecutÃ¡ndose
**Error**: `Connection to node -1 could not be established`
**SoluciÃ³n**: Verificar que Kafka estÃ© ejecutÃ¡ndose en `localhost:9092`

### Problema: TÃ³picos no se crean automÃ¡ticamente
**SoluciÃ³n**: Crear tÃ³picos manualmente:
```bash
kafka-topics --create --topic input-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics --create --topic actions-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics --create --topic output-topic-transformed --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics --create --topic output-topic-json-converted --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics --create --topic output-topic-action-a --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics --create --topic output-topic-action-b --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

## ğŸ“Š Monitoreo y Logs

Los logs de la aplicaciÃ³n mostrarÃ¡n el procesamiento de eventos en tiempo real:
- Procesamiento de Kafka Streams
- Persistencia de eventos en H2
- Actividad de la API REST

### Nivel de Log para Desarrollo
```yaml
logging:
  level:
    com.example.kafkastream: DEBUG
    org.springframework.kafka: DEBUG
```

## ğŸ‰ Flujo Completo de Trabajo

1. **Publicar** evento via REST API
2. **Procesar** evento con Kafka Streams (transformaciÃ³n/conversiÃ³n/enrutamiento)
3. **Persistir** resultado en base de datos H2 via @KafkaListener
4. **Consultar** eventos procesados via REST API

Este PoC demuestra un pipeline completo de procesamiento de eventos con Kafka Streams, desde la ingesta hasta la persistencia, pasando por transformaciones complejas de datos.